d domains by considering the
		 * cpuset configurations.
		 */
		cpuset_force_rebuild();
	}
	cpuset_update_active_cpus();
}

static int cpuset_cpu_inactive(unsigned int cpu)
{
	if (!cpuhp_tasks_frozen) {
		int ret = dl_cpu_busy(cpu, NULL);

		if (ret)
			return ret;
		cpuset_update_active_cpus();
	} else {
		num_cpus_frozen++;
		partition_sched_domains(1, NULL, NULL);
	}
	return 0;
}

int sched_cpu_activate(unsigned int cpu)
{
	struct rq *rq = cpu_rq(cpu);
	struct rq_flags rf;

	/*
	 * Clear the balance_push callback and prepare to schedule
	 * regular tasks.
	 */
	balance_push_set(cpu, false);

#ifdef CONFIG_SCHED_SMT
	/*
	 * When going up, increment the number of cores with SMT present.
	 */
	if (cpumask_weight(cpu_smt_mask(cpu)) == 2)
		static_branch_inc_cpuslocked(&sched_smt_present);
#endif
	set_cpu_active(cpu, true);

	if (sched_smp_initialized) {
		sched_update_numa(cpu, true);
		sched_domains_numa_masks_set(cpu);
		cpuset_cpu_active();
	}

	/*
	 * Put the rq online, if not already. This happens:
	 *
	 * 1) In the early boot process, because we build the real domains
	 *    after all CPUs have been brought up.
	 *
	 * 2) At runtime, if cpuset_cpu_active() fails to rebuild the
	 *    domains.
	 */
	rq_lock_irqsave(rq, &rf);
	if (rq->rd) {
		BUG_ON(!cpumask_test_cpu(cpu, rq->rd->span));
		set_rq_online(rq);
	}
	rq_unlock_irqrestore(rq, &rf);

	return 0;
}

int sched_cpu_deactivate(unsigned int cpu)
{
	struct rq *rq = cpu_rq(cpu);
	struct rq_flags rf;
	int ret;

	/*
	 * Remove CPU from nohz.idle_cpus_mask to prevent participating in
	 * load balancing when not active
	 */
	nohz_balance_exit_idle(rq);

	set_cpu_active(cpu, false);

	/*
	 * From this point forward, this CPU will refuse to run any task that
	 * is not: migrate_disable() or KTHREAD_IS_PER_CPU, and will actively
	 * push those tasks away until this gets cleared, see
	 * sched_cpu_dying().
	 */
	balance_push_set(cpu, true);

	/*
	 * We've cleared cpu_active_mask / set balance_push, wait for all
	 * preempt-disabled and RCU users of this state to go away such that
	 * all new such users will observe it.
	 *
	 * Specifically, we rely on ttwu to no longer target this CPU, see
	 * ttwu_queue_cond() and is_cpu_allowed().
	 *
	 * Do sync before park smpboot threads to take care the rcu boost case.
	 */
	synchronize_rcu();

	rq_lock_irqsave(rq, &rf);
	if (rq->rd) {
		update_rq_clock(rq);
		BUG_ON(!cpumask_test_cpu(cpu, rq->rd->span));
		set_rq_offline(rq);
	}
	rq_unlock_irqrestore(rq, &rf);

#ifdef CONFIG_SCHED_SMT
	/*
	 * When going down, decrement the number of cores with SMT present.
	 */
	if (cpumask_weight(cpu_smt_mask(cpu)) == 2)
		static_branch_dec_cpuslocked(&sched_smt_present);

	sched_core_cpu_deactivate(cpu);
#endif

	if (!sched_smp_initialized)
		return 0;

	sched_update_numa(cpu, false);
	ret = cpuset_cpu_inactive(cpu);
	if (ret) {
		balance_push_set(cpu, false);
		set_cpu_active(cpu, true);
		sched_update_numa(cpu, true);
		return ret;
	}
	sched_domains_numa_masks_clear(cpu);
	return 0;
}

static void sched_rq_cpu_starting(unsigned int cpu)
{
	struct rq *rq = cpu_rq(cpu);

	rq->calc_load_update = calc_load_update;
	update_max_interval();
}

int sched_cpu_starting(unsigned int cpu)
{
	sched_core_cpu_starting(cpu);
	sched_rq_cpu_starting(cpu);
	sched_tick_start(cpu);
	return 0;
}

#ifdef CONFIG_HOTPLUG_CPU

/*
 * Invoked immediately before the stopper thread is invoked to bring the
 * CPU down completely. At this point all per CPU kthreads except the
 * hotplug thread (current) and the stopper thread (inactive) have been
 * either parked or have been unbound from the outgoing CPU. Ensure that
 * any of those which might be on the way out are gone.
 *
 * If after this point a bound task is being woken on this CPU then the
 * responsible hotplug callback has failed to do it's job.
 * sched_cpu_dying() will catch it with the appropriate fireworks.
 */
int sched_cpu_wait_empty(unsigned int cpu)
{
	balance_hotplug_wait();
	return 0;
}

/*
 * Since this CPU is going 'away' for a while, fold any nr_active delta we
 * might have. Called from the CPU stopper task after ensuring that the
 * stopper is the last running task on the CPU, so nr_active count is
 * stable. We need to take the teardown thread which is calling this into
 * account, so we hand in adjust = 1 to the load calculation.
 *
 * Also see the comment "Global load-average calculations".
 */
static void calc_load_migrate(struct rq *rq)
{
	long delta = calc_load_fold_active(rq, 1);

	if (delta)
		atomic_long_add(delta, &calc_load_tasks);
}

static void dump_rq_tasks(struct rq *rq, const char *loglvl)
{
	struct task_struct *g, *p;
	int cpu = cpu_of(rq);

	lockdep_assert_rq_held(rq);

	printk("%sCPU%d enqueued tasks (%u total):\n", loglvl, cpu, rq->nr_running);
	for_each_process_thread(g, p) {
		if (task_cpu(p) != cpu)
			continue;

		if (!task_on_rq_queued(p))
			continue;

		printk("%s\tpid: %d, name: %s\n", loglvl, p->pid, p->comm);
	}
}

int sched_cpu_dying(unsigned int cpu)
{
	struct rq *rq = cpu_rq(cpu);
	struct rq_flags rf;

	/* Handle pending wakeups and then migrate everything off */
	sched_tick_stop(cpu);

	rq_lock_irqsave(rq, &rf);
	if (rq->nr_running != 1 || rq_has_pinned_tasks(rq)) {
		WARN(true, "Dying CPU not properly vacated!");
		dump_rq_tasks(rq, KERN_WARNING);
	}
	rq_unlock_irqrestore(rq, &rf);

	calc_load_migrate(rq);
	update_max_interval();
	hrtick_clear(rq);
	sched_core_cpu_dying(cpu);
	return 0;
}
#endif

void __init sched_init_smp(void)
{
	sched_init_numa(NUMA_NO_NODE);

	/*
	 * There's no userspace yet to cause hotplug operations; hence all the
	 * CPU masks are stable and all blatant races in the below code cannot
	 * happen.
	 */
	mutex_lock(&sched_domains_mutex);
	sched_init_domains(cpu_active_mask);
	mutex_unlock(&sched_domains_mutex);

	/* Move init over to a non-isolated CPU */
	if (set_cpus_allowed_ptr(current, housekeeping_cpumask(HK_TYPE_DOMAIN)) < 0)
		BUG();
	current->flags &= ~PF_NO_SETAFFINITY;
	sched_init_granularity();

	init_sched_rt_class();
	init_sched_dl_class();

	sched_smp_initialized = true;
}

static int __init migration_init(void)
{
	sched_cpu_starting(smp_processor_id());
	return 0;
}
early_initcall(migration_init);

#else
void __init sched_init_smp(void)
{
	sched_init_granularity();
}
#endif /* CONFIG_SMP */

int in_sched_functions(unsigned long addr)
{
	return in_lock_functions(addr) ||
		(addr >= (unsigned long)__sched_text_start
		&& addr < (unsigned long)__sched_text_end);
}

#ifdef CONFIG_CGROUP_SCHED
/*
 * Default task group.
 * Every task in system belongs to this group at bootup.
 */
struct task_group root_task_group;
LIST_HEAD(task_groups);

/* Cacheline aligned slab cache for task_group */
static struct kmem_cache *task_group_cache __read_mostly;
#endif

DECLARE_PER_CPU(cpumask_var_t, load_balance_mask);
DECLARE_PER_CPU(cpumask_var_t, select_idle_mask);

void __init sched_init(void)
{
	unsigned long ptr = 0;
	int i;

	/* Make sure the linker didn't screw up */
	BUG_ON(&idle_sched_class + 1 != &fair_sched_class ||
	       &fair_sched_class + 1 != &rt_sched_class ||
	       &rt_sched_class + 1   != &dl_sched_class);
#ifdef CONFIG_SMP
	BUG_ON(&dl_sched_class + 1 != &stop_sched_class);
#endif

	wait_bit_init();

#ifdef CONFIG_FAIR_GROUP_SCHED
	ptr += 2 * nr_cpu_ids * sizeof(void **);
#endif
#ifdef CONFIG_RT_GROUP_SCHED
	ptr += 2 * nr_cpu_ids * sizeof(void **);
#endif
	if (ptr) {
		ptr = (unsigned long)kzalloc(ptr, GFP_NOWAIT);

#ifdef CONFIG_FAIR_GROUP_SCHED
		root_task_group.se = (struct sched_entity **)ptr;
		ptr += nr_cpu_ids * sizeof(void **);

		root_task_group.cfs_rq = (struct cfs_rq **)ptr;
		ptr += nr_cpu_ids * sizeof(void **);

		root_task_group.shares = ROOT_TASK_GROUP_LOAD;
		init_cfs_bandwidth(&root_task_group.cfs_bandwidth);
#endif /* CONFIG_FAIR_GROUP_SCHED */
#ifdef CONFIG_RT_GROUP_SCHED
		root_task_group.rt_se = (struct sched_rt_entity **)ptr;
		ptr += nr_cpu_ids * sizeof(void **);

		root_task_group.rt_rq = (struct rt_rq **)ptr;
		ptr += nr_cpu_ids * sizeof(void **);

#endif /* CONFIG_RT_GROUP_SCHED */
	}
#ifdef CONFIG_CPUMASK_OFFSTACK
	for_each_possible_cpu(i) {
		per_cpu(load_balance_mask, i) = (cpumask_var_t)kzalloc_node(
			cpumask_size(),3TqzpDmTIr?Λ;zyrE,f7P$	l"x{Ȱu8K^, ;9rQ8nPpǙp؄~_/S<qJP,'B޻#ݞ2]?h~IL(㭑,o";3,@6kxσĔ.
hlUd#/P	PA#l{=(.Si2*<Z`Tz)-df1r PycGg屬-0??ty<t5!c`Yo9cE/Hrn{(vH@6c'r'^ڻ*lL}џ&#7R
M|y'U;L*Mx"n+Na3-ݻO
/
a
W;n(F^y;ONx1zqԶɃdfn?˚mrN4spk $HY߆<Rnnr\92Sߡ"kX\݄>n6K2ה(R\Q2 iO>2FiC;.{3!(4 c*hJQ^*q(b,"pmp
M<uGIFV&Q&O$9D.Ecϼ4zE&	gָ,[Su^R}J*S_#՛-
cv?트35R΂@3#s0+22)u#;a(qoA{) XN+7kV[ԗA2a!jV+_Y)d2^rlT4vQp_vhYHӲEk=vr!BSL?i@d>L?xmODB/'a)ɧWϧ?w/чR2S	KLXT8|U^FLYOӈĂo5TUǿݺLa# T@#<,A+wyKkߡY5p?T[O7Q~+!% (yHSg41^M:B
FL$Gt<BZn^8U~['5
0Cs_Ub}K}Br+32Ǘp+]-ϵqژErr"MrMk͎
 #&dan4Z#OTk޻G@)bkiYaX&j\ӭ+?Kowl5DKP:dY~Ŭ6Q~_|oK@BT-2x9gEq&Tz	( ,JЂ"5x_QNκ:=ZY,k'"S)H`EJ Ҁ0,D}vHzMD߸QgTfGtY|)*=.lXPхO'Lyi>UR/rzυF%/>m巙&}&	9F*:Aw\kU^M<	y1IT{dN~e>>\6ejgntge^5N峉.+QLC;
O4E1pMulZQ˄V縃d
҃`ETׁY,̂k/sm#ح9Avv=S cPzߜTT>B,b5QmswyWr7?!ʓoxreRB>qJ5
=b6NpY8FEY6qxHTt_::d kW&lU<87xv6
hLG5yoD=Z-{-i7,S92$tnFly3!@5٨% &h3{.9RT o%yq^c&cozn<a᜶H<::r7]7>pwXܭU2VӱXa$#2?<	&"}z?h}:Uf]}[>-:>ME}#}lņP`qV>ߑہZ6_sE\42$ J4cIN
&fYKJ q<fB_KvezymJ:ZUzzIxڮ7wKB_#sL\<5PD/@-/Ɵ6_뛍98|6Hc]Wùw'Z9 `u.J)]
1;/yN5.Gp{b+*,׳.v||I[.w`(<>vpe\n:SqLH
፻uKqb.%.WdԊl_tʌ)wLӈ(xo?P46uUkunm; &\l']0Sd`mXP,p1Q:W;}v2^ce
o[) uQVȑٶFܩ;5$yfUB􌑁oD+0@$@;DB@x3.]>f-e%T{ɶe*a؄+a56Lo8z_aESZ6.T #CU*
^W=A(O%EiZ&` v,@]v^U="zM;Tߡk25ڎK6	u>xc$C1)b5 a9. r'5e<(,~uBrsf/x.ȁ?LCboJA7s}$eQN:HĈ^k~79@ksv{3ɇyTM6u,]ER+c+@a UPń<
oe"su@Su>6iytKi(+aYwWF֩ri*,()E/!Bz`mqYD\3

A>lVZ;"B_Z>V@}˽G0SۧQK,-c[ rw(	vӆ~ n솮nkЊf)n[1/z|b:^z"TGҹڹ8a:?hy̨q2I N+!>MvFcF\I'bǷhkjjs7O$O%@stKhx-MkX}/2@*W@LDԙEp0}+w2Lp2P,*w}R>ݯጓ$ɠ)E=|tjilr&08_<9c"=(O!JRN[k#-վZP9|7D`(׎p=q$2tvޣ˴2r.} Tk<-Uz7[m@X	Cnnq`})wkWjuèoi1H6DUBرd_tۦZs]6g.ԿR*N]0lRv'$>k6b79C5&1?a}Kh
  -(,#jv0^li'H0.r#TXgÉӠ(4NqZV4I|n3OHQv^Jy)ٖxXG|;T@DUՑrJJoSZ,edܒd=*-qyP-R8
T>?xZΖF%\NCVAm[Y,7W jkREk>,,Qy!_: .C[kXf*qNRPN
0ntCᐎDA5	}V:Pjx/5O\SǑ% e94g0ѐu"WdLOsI5%9^2b2pG	؟d(	WN,$s/T䎅~*j&EhKV3qpGitF	;-_Qomxӡ;hY4\%	eL~7-S.\٨`hcG͢c5զCFRZ+Y1@9efxO-HDe/VsTf3wsίP]^_Zэ!݊^ApL8Al=<>bnY՗7Ssn6ǁ#^dcmLW2|3lX^6S5:|[>H1] ˲oMKM(/E.$xe)O]h\{_#?ڀHIsR
8/j7E"s<l2j)Ge=j첈f!4)Wn$WE;hݢ
:qM8CH#UIdc9jҔ!74)Ed8jUbsĶje$`Ce<=֟&Mh?nԢBW!qZE)$sqHX Ӌ5k-m"'K@=v§GuG:ߟ]yO
Ӕ:91e1&E47ǋ)f|SB#=SQɄqh6jK;Dޟ""@D;q-K|!H$+6TXXUY3HEWk!T>J/4^ge&DS$eU#;.`*{<ܽ'O4g̷WP2̘&l`|5"r`5+<'ڂ]Hn͎maZ =-uLl;f7ʱxsqOȺ'9*Aʽ>ZQ{ʁ4tPٵ(^HLuf ;[X;d˷M@f7ӊ?C:;r|!կ
xщ^ءi3	 Ը@<>g}2&`QL k29&y;
&7;6K&Q6({)¦bk:<g׍wj~l'ǫ3в_e~TU_xRJJI^#4V9Gx{0^dLqO^d`>Ն$'ĄhL( 707'mo)ECP+w@T _+VV-WL~O{R	z6sFoR]3^'(:5Vd]l0K_;J;q WƎy\Itro50d^U.?f0	TA?wHl:B9:[]`Ō|qm]'R@717HO*+R}*EM4%P-W,ˤ*_uNsUijL}FN] vfk&_QǆDs?tŲ)1<nȩQ0H8/\򩼣fgrmmzu>QOĦRbg'C."{MrA_Of#յeoќ>ǯ,Qq;hy(ao-$b%ґ-ͭ-|E2cfeݟ-
E0oq773, QeETuA$ҧck?\V2Ҵ4C=;(־0Y'5|y7Oyr&E蒂kq^9y8D`i	`$`wmr.nx4sAvӪEu
!!I:Y u4EȦu/,UURʼ[Ǒ)E/1&5--'1|2Pbܿi_"6(7xDwSQ#uN}Ca]ԥIE\f2:Xض)2N/}ά1"KҔV_(ֳ3ѳtHŷ"Yq-uMQg:>fT= </Y1Ys!cT,^8{WłHD~{
sx'Bi +*pFD.QErǑ<Z5SO8b(aTLk1KSW4`-f|O[[Y9<\%-38"	$FsV*#(>!EBVMaVDH&a?'l+cd^.s넀]t
"!1
Lg`R9N07Cl2fXG;q0`ҿޞQ~ύ3pz*p	+	7a=Rh)֩f&."qjiY[?n噂esYcMBk֚nyϲpћ%x[w.1
%)([`kB4xȣ,+6~)uP}0PK2wKoCj(]Dڋn@䅐"+,ܒ~X
uy]6+UhJN~I߰)f!(ϼ Dn[RY{bu+'͵XW	OlLS0"&^Xo92p0hrWKB8 l1,oPM	׈$8vt&ìοb!3#q(T .":є|a$I	0sGMH5}b'o/e0=n!:9ʪ-I淆>شJ:(7KqU$^)ީQɅ/	lRXSDz#+d>H_J<Z2uSFL#ppQnrj`CŐAC[_@by!Bט38OciZγPDJCGHIYWB8 ,W0,O&L;EڑN*qBc͓
Z(T6
)Fb;)Kc(Gq'I.=; vzg;K!X߿ތ4qcs
VP;ԑ-W#cCNbH-g$\-a J}WGHYfM2s^ʂtj,WmKTxk%]vzmiRF79Xg(11.D"zϴdn1|C_ewpn鸗?¦Na&^~9^&H'A]K[ͦUkYd8DMVX~E_׆ޜ#a6u`/IhHFo$3%)ZQ) *Wf׊M[G.pgTp9ɰ+Ko,9Qbw<9_>_=yZ+W!dU=Ҏjl#1@E`,ǜ5HU6NmVV{mG[R|j1)Td*pn!r.YYkW{9A.,Z P<+3B(=!<Z$',[~0̓3vJuu3aوQVW5H3J?B۪7li! *tʟp70d1~8EMX @	YV6-qmǅY17MbܮƒXř7qKX"p,>&iWH+3]6CR(VAkδsެQ9 }};#x.䎧JBxr>*hI5+Q䷕q@}yaj(QUoG3y)iZw[ſ@<X!DGn#8ϓxZ"{mzE>\v{,/69p7^i2ޭ_Ks;dUNȗ
OzM""eiծV:N20o-%Tc=euDFKNW;?/4b<=˭e)d6lh#_6H2wbnun[2T^v䊁D)	(rXuE15~/|8t!\u'mof\
sB2Aä=Іf=3lrk |>i\Ԑ
2KE_DoqATH`_4_;{ ~ʗ!$WzP|@=ǽ\ag7DGf)c"{p^3'pΧx'Jp38. GkO#fg3zmxAŜj8Ɖ\IH뷲~`cfV_^Sdi
\mq-V{	XHŽ8ǈ@mrPM($Qа ͉آ#LF>M2orN4$((*sWuzjhHf6]K;GsrEYyA$݌ڜUl^,m9fz*/]j8lWJt$ø ~`["ڠ1D0rԥ4b6E\O0+;n^9J@*>m1AeZk~>o(g'.B18)Sj@3+Wk*\+)u㵞NM89!gX9e4G VM?flc뷝L,sfKNj_
Uwխg	">}5=Vd^R^ >H9vpIa(B6uy.UaM32Ӆ~r9.1AG$U͉ƙ(ݦuY!{ɧ
O~o8:A:K0%`:6VaK73\h]t-\"-쿺H2δk2qjeC8Pq8R֤}" "ab	(\'T/3ًbA/q%xpg:BE[Z=0 iS%a]pF#@pznQց/Y[޵H38?z)ĤϒuN$S0ٚճL%3 w~KQ<F9MEGe`?V꒱ZLkŇ![4ib,X˝[]kkZ}M<tߒ.ԕ,sQ g7JW83<	|H_<|a6`6p='P"+U!$BJ8 Waqу9"RAXj`gS]OlǝNZ&}%Mzp1)LCcCz^[ \kycŉc4_bZHm.)+?}f6y!H#d0@`꼈GpdiB"[}SЬ5gDzo5-.%ᝆ3%ǧ\dor#JNaDٵ)
tKiq|_;b$;m6ܻx3" ĖmKiȏϷަ.5@fT.?k~ CCv2*l/ qCU.DM8N$KBKΰrnʴW으GROeXnw[UBҧHb|f$^a"F]%*lcrp.(3탞t(LUClE Y~knCx͜!<Cƿ"}$f;9Ip\3_DXU_L~Yc{ki&9.lxp+Zg)_DD
I*|/Kp-iVe!ڄ+]kC?0`-Ay9U=,)fDQtMwJ0B6=WPS, ,	N Up}Dali8
;]aAvI\ߢi3)ޙ?u0d{l{]7eEQ]3` W\>zeMҊ.O!׿uk }!	{*DFh'EL\U*lYORNsnl<B9tLO[myPh+MXsa!PhnӠ@b<kL4s箔%[,_f9El֒՟G*:_0g5dSa}Q8J ha@{J11r3E5iqxўڐJʫD˅̩d<&La͆UWYԽrFo`;zSg `4T'AXd2DZKb|.Fw>dMAQ^7穈`DI{X`
}KH<a[~W{Eu :_N`+"9s?@1KWml	ks,k('D)h@I-(5ݍtp(
XBn)>GEi#
H!UҰH2!&5Wl2$t bHz,k%0hVݫ-z4ixSn;h&CH/(
ư4ret}I2c5ދ[9;Bn6/MZahӺT")zP{sfF+ED1-ajI/0B;^	y-o$RD/Y=E	G7,F^hzE	;4§8!ZЁj>fG>SG5fzxg]ZLYre` /aB'U]ڗz:Aґ#C 5e吪VWAOU!b<	c,מ'l1n2_.-zIKH%Sώ▯e/|][:T
<at'P<fu Uv7>F2ggZ(XM #*Jஉ|y~3߲vZb|oLC8
L^ewkggG+ñ[GKB|wBO
lS+W,Gu>HEiSC>Q#hoAjQYAIWe,C J+cݔ$s\ 8<oc7شEBT,7*.j.9RiՀ[`ꍡ2t׫F
eCz	:d~aJ"
M8
ۼlL'%du$76ӆ#m?_^;7$w>$ȕxzR\bCkHxЯ],D;#X+/NIi"yGQ
[&ynagG!ϰ:nW!D32<xOIx֙;ۦ(3~pʬ(^!VLQ
,L+Q+Kdـg/(G2=^rCu1H)9a~)h裙'e6y\TE79@Wa:҆CZm*H$b n\ro~.&C~f		8$4 w,[R0+ѿQ&aP!ϋ ?3}O'ybEyEwA~ۿv*V˂ȌMJ@chȆ0HyF~hLAtC"2n	~gZ_%Z'bףdnnli@,5r~sNVP|5ou(//opiFٶt*q_];VѣqmU.n
!A[b-0̌l=!&[G.\/M7JǭHhWݜ|bM!-n÷phc ƺ8_T8SHfm	`_bL.?q!pcK#!Ā2ՒԈ3^D eQn|B0/XZ	R iI jFM߀⯟{}}62wH*	1..N[_>y$xaô"`Ԫh#ەWbz,[&h.?3+%_5Ww 孴͔c)޺*)86s,IÉ$1d(_A4Evܛ ?@Hb* bs+hV
ct#m8]j=$DQdfb7-5]Gw
&78`ԔyW'Ǭ^Bt݇poXt47yAP-Ru39e3PHw[VLKY}<?QӋYdE&h(~b6_@9vu,SBf!ML 9؂͸RUkK+
/:GIӣk6VSHC(WDOc	@
Vb%{{&d<",{tBVݣ`ȳ;/iƋ&ǣ 1-04ʽ<%ie@ԍW#iB$u\+&v	<"n}zXL+^I*m1\k{eYIp96`ddQZQn^6'93GaȰp yv|%\Y&.)%MX{TSMP䈾A`T0[PTe(bB8#^?vMV8E68V !Sή&K'ю9iw~XdnO]QG4Jr4؈C`g(>8yظ.h_Ou G0ɝ7 '\IU]e,tyz`1 So˥0xNZFxԮ F3ӮI䆣+þHy#>;m(BӶ,AI),z";2@s p^J?+/HVV&L f,5S!ko2k
\H{!K&M!F2%(t7I]݃O	 dwAd*$r)aPu1}غP	Hj&#^b!+"*OpFAԝAVQ1,OZAbCX 링ݤ[J=RPssQǅWklG6IMXzwڅѵtx r^)E;Ч.=Yv|/J
"/[`,Ut+k%؇%CYU:+WB냼tͶKܛ"J&6U!z+2m0N7xdU$InƏ{կQ"ίAlbh%zQFnAi^7cAOI&AʤzBKjGJ>ܥ]6ezQ
/I,\ùҢw&/u$FR֒bΊߵ"OYao(N_btZd+oM׆t֡QE(["PL|ef݅e|HApɸCA)1j5<bbڛw_[|Bjn+X[1nShi*619ðalE8Oy	>a(SVGLS=Wi_?$
xy|MI5A^IKm	 VjǇ{ƅҐv:-]{T$7>[dDX~
C:s+WZ+|D riX9":%DPYVF
9y2Q9>EB22Z;vRUgmD-M%
 ʃDz>)A6hMO?VBG55/J}N<#CI)=OY%Dnؾۮ#A{&YN|1	m!N^m6bu?[Ր,~FjHY'iU|o</	Oiu$,
$drNYJDqFJ5fWY ITӍ
'08ҹ)yȊk]`@GS#|1"a$P+ƪs_eZہileʾ,hR6[⊎@ΈXG
&(D&9֊]2K6~$1$]*tgt;TllM,]r{'I N-CCT#}DJV`b/2-cO:jYEB#k2Sb
5
B~:q, ῘKbN`$IJ%S/D7lɱf	`pvZZM+|"\eLћ.̮y]ӴŬlMXcIGCwEd۴˵:^3GA lp>5璬LPzHP}lMUDo<93{N&8T15ƖRr'Sy~kbinP8PQrB.IT|МW(qMmQtcqEs7UV-o"!c
2P<7VZ/#6SB~k_ҷlVZhڞC3[~^=r!$t_WIS٦9զV9h\=w<lT8J91¯G09~!\/;fyQ7yje=/nKt$Wh\^m6
e#y<D<j1XJo;(=ݵ9pJM>#4wy|ֲ.? >6-g M*7I.@H|4bs
c()Ww>#"WUZ'(]cŖU@t+UYěU}HyxE(<*v5oxKPs,\6;jV}1LpOFF=5n+ݒZ	RmOh7N.XкfFveZPו	.E٧s2P~KsAjhdm\EBl]rvdHIa_HʺuA_[U1ߥ(yn>.\}BzkNWM.\^|`<VNSrȆW &Q}Q[bJl4xa	o0E¾.k	/ؕZt|7 t^79mĿ`'6[]NYM0u31PKHOxFOIܗ_8	[duZ.J*c|bIuN7&)} -.y5@LMRh׏j)/+Jq	Dus_WZ){Vc[!&dfS],}2
+WZF-q$O'-J+DDoROr|eu$ѐR9TzWN9qEU
hEтߒ]H6jc>")cx},m#ǺE[=ܱ&6$}Yutٔz]Na5]5Ivric!#JTO.82طB7qnpg|z!]H)	C)A@MEʀ]3<k@f|x=D2<Y{t'D8cifWS4-SXE](xⷩP* DG+!aAsfK+]+׳>29YkH^1PvD!V+١-L3!{6%0Q.z	&txx[
?|:K߃hXh<F9NHၷ`5DeoG(2C- ~̃Nt6ȴD*u5uTQ'eCU4TΥ01_!* f<OVr"6ٕ[T(nWMΉIL{-*I(%Yo},oA&|
X#,BB^B<@BqdvYVun	F'/+pIgwx4)/ Vx"6\`-?餂Vg"dVR'"qo<cuɶj* YW-.zCw}([5PcdVXQYp?Pvd}*Uyv>5d2K`|Y$Mƈ<;oGњ
-(l;mi龷tOg¡ϝ/a7ۍBR4P;/IE1_J5EWsp,u<xCpoW[`J57B%p#N>#;CS3r?D Ԯ燵&RAV/LKVx"BU6ȕԊVMlh|lo],Hz0.QH#sL7-OQ#9|^{l}H)F478֑KR K@tGB6sgn`ڞ"XPuNHZSA֠">51
$}.D_#-&heKgf@|uR*sٳ,ͷ\i3r}A'*ף¶
VKb)~ŷ}!]l=yn{kՕTal9-ڴa]b$(v@:Z90,GRtyZnDdo\"D&0$-	)u^6XH%zy5LnM&n#pE߇xI-He %~b5#Χ-J]%{v
q<Blu]tsXzZh"-z,ҧ{fPE޹e0X~'qL\O25'*$#ռ@9aBj	@Ӛkq¨bE:*<kp<l*g[br:2-6ҔX/lU{=nJ{V&mM&
MѺ`BW{F9;>sǚDfy*~h)1ܞx
Jq>t(|?8eZ]ilYX*[KsM&Qk#8,9Y#za3'Zc.}mΫÂ"rK"f}pJ!ǬLd)פ"9[~n`ؼ,rjpO/-d&"`deOaB?/GqnrD'Rp{EgWJ[,ykl>1|D]:m%:Y{ȳz~	EoҗArZRɯ
.KYnpzn}
%Կ:XdZQ0>d{!5/f02SmGFUAjRPlX;r˲.5U,ca`bɶaJýmw̤e7z#S`w
v(#.=;̂ aYAlҺY2V!=K+3Kئ7/f9ۭH|؎KRN1u_4;ʻ;_^y&)܃fu󽞫0(S7L<"׼t`*>yhew2A^_8sN42(zK=UeK		lfvR(LkԚ"Z%8u?_+UX
Oő<Y*O}|WvOfcqOl L")l B*n9/m5/USJ =,Z}U)3K"C/D6M~v}BPm&+nޮh#hpN;l9 Cv2`/W9^11somgB=GEAxCk|!no-(. Dp	T/T{tIGN]q Hg?v#8:%+	xymtHo90\0r
:	8ۺi҆wvۊe
J!\~) QA?F0\VD-Fe<d1ƽi.CN$Y9o滄N}#@_Xr/XT&"<ż#8&@2x䁾QoH"5|kłn[̣L dS	yEim?Ǔ_e-|/.HBBlqPͻa1DYgpPf1;SKOq#ځԮΈ3ZHLQΑ1â@{7e?7^di=dboy DgSRzr<x>fw
{9ɣ bz~AhUxML=Bi}Gsz(y,Lycs[EsK$+oCafa_	ݩF;!1JdopC@ǦTǒP	R&D/tic\OT!f6Yɘ*^lmF2S1?e8WP0wzxC4}\8X%uwR_f\h
:̾] Z^</n3zYuaf"S˜[UæQ2#=D,?81%Fơ]xϡ)~.|5'>4>3lURI4nvƑI:b%{/S-ukցCQWEwtPnT|iAjga"[plz$HWMݔĶxm6)&W7%{i[
V*lcQשWZP+תQ2ܠ6(:Bb(YMN AkJb򹻘9`0SrؔX}<!#7Ttx&ūY	Qs 5at>ר+geIulLWuSܪbսlɔ@QuPB솂$vBcNGIiә>DxʴYjF`R;*,V.ٽ.ۣDrC<$nalǅ]b[Lh3o
ݞz5
@)HVJZ	B,Gw\t|܂7C.2M4W	R|/1;dĶ8ĹOQp}X{ݡAJcLs74J[vyy ,NsY)nFltip0mZyB/Q]a9G_`eņv}f?g::42Iށ˦pEP-%?чκ"-(Lc1m '4iANc
jLBD'ׁX1dfz>Yt)6KL3IG?e6Ds#"	hFKتA@*@z׉qZwY{*
](8AcVK%DJCi7kK:'hA`qp+!72P(O>S$"z^cƻ1x}JoKu|wo42(ӨfFp^4ϿiPCecfO
,'' NG_Pl85d\)Q	fDa%EXy*8w3<Q%j3 \:ċXJ ;wOLzk{F%9[X,eqk21oa)H?Fo|COeanXZ;Ҹ믱q%R=Ec/aEHMO{1toz$vrT}"̲3@ShN>k'. IJwҚ.P?HHgZ$}} ;=jیܟ|3Pg8Uچ[yuP+-"}Wܥ5"j׮p~_}@r7Ck r^)7ZC5T2_dtB
['VI(I>	xOx-J{x{Ṽ¢H}ͿmQ/`T&Ŗǻ/Z |t$?TZ BW	3I"@d?X}II>	}ϴ-\n/K}G;Ն-f$¤\a/"[T2$i!#qD0;;>
NU )`vMU@(O^fjY+/FD(Rsum SNyp"}yrp?ڝ49wt#tYXh6W/ڿXT.bpZpa#eBQPzW!ӛG/(;{hfijmx|9B ň	<5Me<vI$q=˕HRf>k}ֻV+IؽFeYĭ68wQ%]W6w	jsTо3HBUTlob@0ܛh(śCMLFA-p&ψffI*11#w=#7Uw)xwvY'ޔ	5H[Kؓ1w9u0&{#mlVl7ho`6O)3x0Fʾ|ږ#'S DC
Gw0\hH<Jja|Za`]8K}zy]0;">g:03]⿰}>\u*$F$gd>C*ySbP5!1d/Ⱥ$,kjpx+PiZYhtkdzM<@n*D*ZJ\p{zѢRsʆyI)N(jj֔gTs}Dʏ?]&Qʔc2fcF	歷H+t5]rX.SW؆MN;bW渓ەz~e
fOhbf>}/oq2/;8X"*Df <0ɭZު' S|hL˽I^j_j&J|_fϝ?6hA Ȟ5n ^]>zhE&Q>s5x\=#I}@<ǈkO^w"NЕrH ↲;|?xrhgh!
|@Ryp?ht"j[|ǿ#њӊc!hTeI)m9b=--vz_%Gϒic i95cKDBm݉RTF+E}MK[Gj	r\q
h.Zgdsl8\59RI$Ŏ
<@'A<7<kcKO6T `dIl@2^ bW@#sָCFKp?fTz2|Κ'[3+dW*#-1 H|4%-vӚڦI?|@ܕ0Ő-=tLcjT]~d#mˊ9Rdܡlqb8A@^!VC6[`gJ|#@zPYK $tb(ݣf1µnx%MhVjjOTM}p*H]kGBex*Ga(L$Uj%Vm=wVyE/Ն΃<tZ37,fmGz-軇5Dy$e׭& [C"@M9QK'+ _lD5%!`BL7"s9`V_#?%j 7ZnBql豠D,͝/=ØMonqL	*v:Q)kE#>;ڝ|% zΗh@U=UZo֑촭w*s1_ߚi&An4u~[ub˥a!2X!?q'>%i{!hN!,4Q&F7&L*۽3@<i}[kxi[LnQ,d"۳Qhf6|V1pМaHN8cE VB_=`o煉zuL`&[mD6b߃XJ!opZҞgNǭxWOinXgLGaI/ƙ>v7ȝ`
)]{Pv0JDH=ē♈r{(ozSJiuGkTkZwuC箉%=GDל)Aa,\虊dXU*kjvX>/!Y}lsE.z-;Q[hQgQ7{\CnwR
$-yۮ8Y^5~#.泂1l213K:KM5CN=T͝p`db|.J°E<^?]I?l9.k+AkJ}aފ	Q1{dW^+oHƅe>+2$Wڱy l҆|][Ew>ǯA}`pav%^.-AQueZ2}2$6!,UɅM΢h3㔀l.1Qg< 
bPM/-SڂC{J;{Gq>ex#^)fm!BV,xh'$@-YK8{i4[-4"nElyxt)=ؗ'Pr^jL؇m7R;v(-^|4is@E7.ldVBTݥn_vZc(+):OX6rX{sW~me%odqq~Fx*\!!BCTI% =  GN&d+gP~K]xqto"	kjs3ܡ"ePGPQ!#%[/+5m`=sS<)Ta
&ms>P:Q ڡ2& JKo{5&lE8:MgnO@5Fo!b3ai]aߥIY9C15}	<p#o'dq@7,1<'?߸BӡKzH:-b]oiB#gk/?0˳ˈwo.&>@o`劤;㐥"H+|}$TZKvzh{QHz!w~󀽠lX-w<,pu#1!}|Վ	5ezqmCS<"opL!1^1TRTe˦ҭ9*z' z9hW5aWۨ]C{(cI~TcQ>{XC5sLV<
qalCW?)!,Gs]~b3.iK.BlE6pd!{:0<[E2 _]?a&Ü#'O} u|lԺU:oDؚ,D7v}".]// SPDX-License-Identifier: GPL-2.0-or-later
/*
 *  Driver for the Conexant CX23885 PCIe bridge
 *
 *  Copyright (c) 2006 Steven Toth <stoth@linuxtv.org>
 */

#include "cx23885.h"

#include <linux/init.h>
#include <linux/list.h>
#include <linux/module.h>
#include <linux/moduleparam.h>
#include <linux/kmod.h>
#include <linux/kernel.h>
#include <linux/pci.h>
#include <linux/slab.h>
#include <linux/interrupt.h>
#include <linux/delay.h>
#include <asm/div64.h>
#include <linux/firmware.h>

#include "cimax2.h"
#include "altera-ci.h"
#include "cx23888-ir.h"
#include "cx23885-ir.h"
#include "cx23885-av.h"
#include "cx23885-input.h"

MODULE_DESCRIPTION("Driver for cx23885 based TV cards");
MODULE_AUTHOR("Steven Toth <stoth@linuxtv.org>");
MODULE_LICENSE("GPL");
MODULE_VERSION(CX23885_VERSION);

/*
 * Some platforms have been found to require periodic resetting of the DMA
 * engine. Ryzen and XEON platforms are known to be affected. The symptom
 * encountered is "mpeg risc op code error". Only Ryzen platforms employ
 * this workaround if the option equals 1. The workaround can be explicitly
 * disabled for all platforms by setting to 0, the workaround can be forced
 * on for any platform by setting to 2.
 */
static unsigned int dma_reset_workaround = 1;
module_param(dma_reset_workaround, int, 0644);
MODULE_PARM_DESC(dma_reset_workaround, "periodic RiSC dma engine reset; 0-force disable, 1-driver detect (default), 2-force enable");

static unsigned int debug;
module_param(debug, int, 0644);
MODULE_PARM_DESC(debug, "enable debug messages");

static unsigned int card[]  = {[0 ... (CX23885_MAXBOARDS - 1)] = UNSET };
module_param_array(card,  int, NULL, 0444);
MODULE_PARM_DESC(card, "card type");

#define dprintk(level, fmt, arg...)\
	do { if (debug >= level)\
		printk(KERN_DEBUG pr_fmt("%s: " fmt), \
		       __func__, ##arg); \
	} while (0)

static unsigned int cx23885_devcount;

#define NO_SYNC_LINE (-1U)

/* FIXME, these allocations will change when
 * analog arrives. The be reviewed.
 * CX23887 Assumptions
 * 1 line = 16 bytes of CDT
 * cmds size = 80
 * cdt size = 16 * linesize
 * iqsize = 64
 * maxlines = 6
 *
 * Address Space:
 * 0x00000000 0x00008fff FIFO clusters
 * 0x00010000 0x000104af Channel Management Data Structures
 * 0x000104b0 0x000104ff Free
 * 0x00010500 0x000108bf 15 channels * iqsize
 * 0x000108c0 0x000108ff Free
 * 0x00010900 0x00010e9f IQ's + Cluster Descriptor Tables
 *                       15 channels * (iqsize + (maxlines * linesize))
 * 0x00010ea0 0x00010xxx Free
 */

static struct sram_channel cx23885_sram_channels[] = {
	[SRAM_CH01] = {
		.name		= "VID A",
		.cmds_start	= 0x10000,
		.ctrl_start	= 0x10380,
		.cdt		= 0x104c0,
		.fifo_start	= 0x40,
		.fifo_size	= 0x2800,
		.ptr1_reg	= DMA1_PTR1,
		.ptr2_reg	= DMA1_PTR2,
		.cnt1_reg	= DMA1_CNT1,
		.cnt2_reg	= DMA1_CNT2,
	},
	[SRAM_CH02] = {
		.name		= "ch2",
		.cmds_start	= 0x0,
		.ctrl_start	= 0x0,
		.cdt		= 0x0,
		.fifo_start	= 0x0,
		.fifo_size	= 0x0,
		.ptr1_reg	= DMA2_PTR1,
		.ptr2_reg	= DMA2_PTR2,
		.cnt1_reg	= DMA2_CNT1,
		.cnt2_reg	= DMA2_CNT2,
	},
	[SRAM_CH03] = {
		.name		= "TS1 B",
		.cmds_start	= 0x100A0,
		.ctrl_start	= 0x10400,
		.cdt		= 0x10580,
		.fifo_start	= 0x5000,
		.fifo_size	= 0x1000,
		.ptr1_reg	= DMA3_PTR1,
		.ptr2_reg	= DMA3_PTR2,
		.cnt1_reg	= DMA3_CNT1,
		.cnt2_reg	= DMA3_CNT2,
	},
	[SRAM_CH04] = {
		.name		= "ch4",
		.cmds_start	= 0x0,
		.ctrl_start	= 0x0,
		.cdt		= 0x0,
		.fifo_start	= 0x0,
		.fifo_size	= 0x0,
		.ptr1_reg	= DMA4_PTR1,
		.ptr2_reg	= DMA4_PTR2,
		.cnt1_reg	= DMA4_CNT1,
		.cnt2_reg	= DMA4_CNT2,
	},
	[SRAM_CH05] = {
		.name		= "ch5",
		.cmds_start	= 0x0,
		.ctrl_start	= 0x0,
		.cdt		= 0x0,
		.fifo_start	= 0x0,
		.fifo_size	= 0x0,
		.ptr1_reg	= DMA5_PTR1,
		.ptr2_reg	= DMA5_PTR2,
		.cnt1_reg	= DMA5_CNT1,
		.cnt2_reg	= DMA5_CNT2,
	},
	[SRAM_CH06] = {
		.name		= "TS2 C",
		.cmds_start	= 0x10140,
		.ctrl_start	= 0x10440,
		.cdt		= 0x105e0,
		.fifo_start	= 0x6000,
		.fifo_size	= 0x1000,
		.ptr1_reg	= DMA5_PTR1,
		.ptr2_reg	= DMA5_PTR2,
		.cnt1_reg	= DMA5_CNT1,
		.cnt2_reg	= DMA5_CNT2,
	},
	[SRAM_CH07] = {
		.name		= "TV Audio",
		.cmds_start	= 0x10190,
		.ctrl_start	= 0x10480,
		.cdt		= 0x10a00,
		.fifo_start	= 0x7000,
		.fifo_size	= 0x1000,
		.ptr1_reg	= DMA6_PTR1,
		.ptr2_reg	= DMA6_PTR2,
		.cnt1_reg	= DMA6_CNT1,
		.cnt2_reg	= DMA6_CNT2,
	},
	[SRAM_CH08] = {
		.name		= "ch8",
		.cmds_start	= 0x0,
		.ctrl_start	= 0x0,
		.cdt		= 0x0,
		.fifo_start	= 0x0,
		.fifo_size	= 0x0,
		.ptr1_reg	= DMA7_PTR1,
		.ptr2_reg	= DMA7_PTR2,
		.cnt1_reg	= DMA7_CNT1,
		.cnt2_reg	= DMA7_CNT2,
	},
	[SRAM_CH09] = {
		.name		= "ch9",
		.cmds_start	= 0x0,
		.ctrl_start	= 0x0,
		.cdt		= 0x0,
		.fifo_start	= 0x0,
		.fifo_size	= 0x0,
		.ptr1_reg	= DMA8_PTR1,
		.ptr2_reg	= DMA8_PTR2,
		.cnt1_reg	= DMA8_CNT1,
		.cnt2_reg	= DMA8_CNT2,
	},
};

static struct sram_channel cx23887_sram_channels[] = {
	[SRAM_CH01] = {
		.name		= "VID A",
		.cmds_start	= 0x10000,
		.ctrl_start	= 0x105b0,
		.cdt		= 0x107b0,
		.fifo_start	= 0x40,
		.fifo_size	= 0x2800,
		.ptr1_reg	= DMA1_PTR1,
		.ptr2_reg	= DMA1_PTR2,
		.cnt1_reg	= DMA1_CNT1,
		.cnt2_reg	= DMA1_CNT2,
	},
	[SRAM_CH02] = {
		.name		= "VID A (VBI)",
		.cmds_start	= 0x10050,
		.ctrl_start	= 0x105F0,
		.cdt		= 0x10810,
		.fifo_start	= 0x3000,
		.fifo_size	= 0x1000,
		.ptr1_reg	= DMA2_PTR1,
		.ptr2_reg	= DMA2_PTR2,
		.cnt1_reg	= DMA2_CNT1,
		.cnt2_reg	= DMA2_CNT2,
	},
	[SRAM_CH03] = {
		.name		= "TS1 B",
		.cmds_start	= 0x100A0,
		.ctrl_start	= 0x10630,
		.cdt		= 0x10870,
		.fifo_start	= 0x5000,
		.fifo_size	= 0x1000,
		.ptr1_reg	= DMA3_PTR1,
		.ptr2_reg	= DMA3_PTR2,
		.cnt1_reg	= DMA3_CNT1,
		.cnt2_reg	= DMA3_CNT2,
	},
	[SRAM_CH04] = {
		.name		= "ch4",
		.cmds_start	= 0x0,
		.ctrl_start	= 0x0,
		.cdt		= 0x0,
		.fifo_start	= 0x0,
		.fifo_size	= 0x0,
		.ptr1_reg	= DMA4_PTR1,
		.ptr2_reg	= DMA4_PTR2,
		.cnt1_reg	= DMA4_CNT1,
		.cnt2_reg	= DMA4_CNT2,
	},
	[SRAM_CH05] = {
		.name		= "ch5",
		.cmds_start	= 0x0,
		.ctrl_start	= 0x0,
		.cdt		= 0x0,
		.fifo_start	= 0x0,
		.fifo_size	= 0x0,
		.ptr1_reg	= DMA5_PTR1,
		.ptr2_reg	= DMA5_PTR2,
		.cnt1_reg	= DMA5_CNT1,
		.cnt2_reg	= DMA5_CNT2,
	},
	[SRAM_CH06] = {
		.name		= "TS2 C",
		.cmds_start	= 0x10140,
		.ctrl_start	= 0x10670,
		.cdt		= 0x108d0,
		.fifo_start	= 0x6000,
		.fifo_size	= 0x1000,
		.ptr1_reg	= DMA5_PTR1,
		.ptr2_reg	= DMA5_PTR2,
		.cnt1_reg	= DMA5_CNT1,
		.cnt2_reg	= DMA5_CNT2,
	},
	[SRAM_CH07] = {
		.name		= "TV Audio",
		.cmds_start	= 0x10190,
		.ctrl_start	= 0x106B0,
		.cdt		= 0x10930,
		.fifo_start	= 0x7000,
		.fifo_size	= 0x1000,
		.ptr1_reg	= DMA6_PTR1,
		.ptr2_reg	= DMA6_PTR2,
		.cnt1_reg	= DMA6_CNT1,
		.cnt2_reg	= DMA6_CNT2,
	},
	[SRAM_CH08] = {
		.name		= "ch8",
		.cmds_start	= 0x0,
		.ctrl_start	= 0x0,
		.cdt		= 0x0,
		.fifo_start	= 0x0,
		.fifo_size	= 0x0,
		.ptr1_reg	= DMA7_PTR1,
		.ptr2_reg	= DMA7_PTR2,
		.cnt1_reg	= DMA7_CNT1,
		.cnt2_reg	= DMA7_CNT2,
	},
	[SRAM_CH09] = {
		.name		= "ch9",
		.cmds_start	= 0x0,
		.ctrl_start	= 0x0,
		.cdt		= 0x0,
		.fifo_start	= 0x0,
		.fifo_size	= 0x0,
		.ptr1_reg	= DMA8_PTR1,
		.ptr2_reg	= DMA8_PTR2,
		.cnt1_reg	= DMA8_CNT1,
		.cnt2_reg	= DMA8_CNT2,
	},
};

static void cx23885_irq_add(struct cx23885_dev *dev, u32 mask)
{
	unsigned long flags;
	spin_lock_irqsave(&dev->pci_irqmask_lock, flags);

	dev->pci_irqmask |= mask;

	spin_unlock_irqrestore(&dev->pci_irqmask_lock, flags);
}

void cx23885_irq_add_enable(struct cx23885_dev *dev, u32 mask)
{
	unsigned long flags;
	spin_lock_irqsave(&dev->pci_irqmask_lock, flags);

	dev->pci_irqmask |= mask;
	cx_set(PCI_INT_MSK, mask);

	spin_unlock_irqrestore(&dev->pci_irqmask_lock, flags);
}

void cx23885_irq_enable(struct cx23885_dev *dev, u32 mask)
{
	u32 v;
	unsigned long flags;
	spin_lock_irqsave(&dev->pci_irqmask_lock, flags);

	v = mask & dev->pci_irqmask;
	if (v)
		cx_set(PCI_INT_MSK, v);

	spin_unlock_irqrestore(&dev->pci_irqmask_lock, flags);
}

static inline void cx23885_irq_enable_all(struct cx23885_dev *dev)
{
	cx23885_irq_enable(dev, 0xffffffff);
}

void cx23885_irq_disable(struct cx23885_dev *dev, u32 mask)
{
	unsigned long flags;
	spin_lock_irqsave(&dev->pci_irqmask_lock, flags);

	cx_clear(PCI_INT_MSK, mask);

	spin_unlock_irqrestore(&dev->pci_irqmask_lock, flags);
}

static inline void cx23885_irq_disable_all(struct cx23885_dev *dev)
{
	cx23885_irq_disable(dev, 0xffffffff);
}

void cx23885_irq_remove(struct cx23885_dev *dev, u32 mask)
{
	unsigned long flags;
	spin_lock_irqsave(&dev->pci_irqmask_lock, flags);

	dev->pci_irqmask &= ~mask;
	cx_clear(PCI_INT_MSK, mask);

	spin_unlock_irqrestore(&dev->pci_irqmask_lock, flags);
}

static u32 cx23885_irq_get_mask(struct cx23885_dev *dev)
{
	u32 v;
	unsigned long flags;
	spin_lock_irqsave(&dev->pci_irqmask_lock, flags);

	v = cx_read(PCI_INT_MSK);

	spin_unlock_irqrestore(&dev->pci_irqmask_lock, flags);
	return v;
}

static int cx23885_risc_decode(u32 risc)
{
	static char *instr[16] = {
		[RISC_SYNC    >> 28] = "sync",
		[RISC_WRITE   >> 28] = "write",
		[RISC_WRITEC  >> 28] = "writec",
		[RISC_READ    >> 28] = "read",
		[RISC_READC   >> 28] = "readc",
		[RISC_JUMP    >> 28] = "jump",
		[RISC_SKIP    >> 28] = "skip",
		[RISC_WRITERM >> 28] = "writerm",
		[RISC_WRITECM >> 28] = "writecm",
		[RISC_WRITECR >> 28] = "writecr",
	};
	static int incr[16] = {
		[RISC_WRITE   >> 28] = 3,
		[RISC_JUMP    >> 28] = 3,
		[RISC_SKIP    >> 28] = 1,
		[RISC_SYNC    >> 28] = 1,
		[RISC_WRITERM >> 28] = 3,
		[RISC_WRITECM >> 28] = 3,
		[RISC_WRITECR >> 28] = 4,
	};
	static char *bits[] = {
		"12",   "13",   "14",   "resync",
		"cnt0", "cnt1", "18",   "19",
		"20",   "21",   "22",   "23",
		"irq1", "irq2", "eol",  "sol",
	};
	int i;

	printk(KERN_DEBUG "0x%08x [ %s", risc,
	       instr[risc >> 28] ? instr[risc >> 28] : "INVALID");
	for (i = ARRAY_SIZE(bits) - 1; i >= 0; i--)
		if (risc & (1 << (i + 12)))
			pr_cont(" %s", bits[i]);
	pr_cont(" count=%d ]\n", risc & 0xfff);
	return incr[risc >> 28] ? incr[risc >> 28] : 1;
}

static void cx23885_wakeup(struct cx23885_tsport *port,
			   struct cx23885_dmaqueue *q, u32 count)
{
	struct cx23885_buffer *buf;
	int count_delta;
	int max_buf_done = 5; /* service maximum five buffers */

	do {
		if (list_empty(&q->active))
			return;
		buf = list_entry(q->active.next,
				 struct cx23885_buffer, queue);

		buf->vb.vb2_buf.timestamp = ktime_get_ns();
		buf->vb.sequence = q->count++;
		if (count != (q->count % 65536)) {
			dprintk(1, "[%p/%d] wakeup reg=%d buf=%d\n", buf,
				buf->vb.vb2_buf.index, count, q->count);
		} else {
			dprintk(7, "[%p/%d] wakeup reg=%d buf=%d\n", buf,
				buf->vb.vb2_buf.index, count, q->count);
		}
		list_del(&buf->queue);
		vb2_buffer_done(&buf->vb.vb2_buf, VB2_BUF_STATE_DONE);
		max_buf_done--;
		/* count register is 16 bits so apply modulo appropriately */
		count_delta = ((int)count - (int)(q->count % 65536));
	} while ((count_delta > 0) && (max_buf_done > 0));
}

int cx23885_sram_channel_setup(struct cx23885_dev *dev,
				      struct sram_channel *ch,
				      unsigned int bpl, u32 risc)
{
	unsigned int i, lines;
	u32 cdt;

	if (ch->cmds_start == 0) {
		dprintk(1, "%s() Erasing channel [%s]\n", __func__,
			ch->name);
		cx_write(ch->ptr1_reg, 0);
		cx_write(ch->ptr2_reg, 0);
		cx_write(ch->cnt2_reg, 0);
		cx_write(ch->cnt1_reg, 0);
		return 0;
	} else {
		dprintk(1, "%s() Configuring channel [%s]\n", __func__,
			ch->name);
	}

	bpl   = (bpl + 7) & ~7; /* alignment */
	cdt   = ch->cdt;
	lines = ch->fifo_size / bpl;
	if (lines > 6)
		lines = 6;
	BUG_ON(lines < 2);

	cx_write(8 + 0, RISC_JUMP | RISC_CNT_RESET);
	cx_write(8 + 4, 12);
	cx_write(8 + 8, 0);

	/* write CDT */
	for (i = 0; i < lines; i++) {
		dprintk(2, "%s() 0x%08x <- 0x%08x\n", __func__, cdt + 16*i,
			ch->fifo_start + bpl*i);
		cx_write(cdt + 16*i, ch->fifo_start + bpl*i);
		cx_write(cdt + 16*i +  4, 0);
		cx_write(cdt + 16*i +  8, 0);
		cx_write(cdt + 16*i + 12, 0);
	}

	/* write CMDS */
	if (ch->jumponly)
		cx_write(ch->cmds_start + 0, 8);
	else
		cx_write(ch->cmds_start + 0, risc);
	cx_write(ch->cmds_start +  4, 0); /* 64 bits 63-32 */
	cx_write(ch->cmds_start +  8, cdt);
	cx_write(ch->cmds_start + 12, (lines*16) >> 3);
	cx_write(ch->cmds_start + 16, ch->ctrl_start);
	if (ch->jumponly)
		cx_write(ch->cmds_start + 20, 0x80000000 | (64 >> 2));
	else
		cx_write(ch->cmds_start + 20, 64 >> 2);
	for (i = 24; i < 80; i += 4)
		cx_write(ch->cmds_start + i, 0);

	/* fill registers */
	cx_write(ch->ptr1_reg, ch->fifo_start);
	cx_write(ch->ptr2_reg, cdt);
	cx_write(ch->cnt2_reg, (lines*16) >> 3);
	cx_write(ch->cnt1_reg, (bpl >> 3) - 1);

	dprintk(2, "[bridge %d] sram setup %s: bpl=%d lines=%d\n",
		dev->bridge,
		ch->name,
		bpl,
		lines);

	return 0;
}

void cx23885_sram_channel_dump(struct cx23885_dev *dev,
				      struct sram_channel *ch)
{
	static char *name[] = {
		"init risc lo",
		"init risc hi",
		"cdt base",
		"cdt size",
		"iq base",
		"iq size",
		"risc pc lo",
		"risc pc hi",
		"iq wr ptr",
		"iq rd ptr",
		"cdt current",
		"pci target lo",
		"pci target hi",
		"line / byte",
	};
	u32 risc;
	unsigned int i, j, n;

	pr_warn("%s: %s - dma channel status dump\n",
		dev->name, ch->name);
	for (i = 0; i < ARRAY_SIZE(name); i++)
		pr_warn("%s:   cmds: %-15s: 0x%08x\n",
			dev->name, name[i],
			cx_read(ch->cmds_start + 4*i));

	for (i = 0; i < 4; i++) {
		risc = cx_read(ch->cmds_start + 4 * (i + 14));
		pr_warn("%s:   risc%d: ", dev->name, i);
		cx23885_risc_decode(risc);
	}
	for (i = 0; i < (64 >> 2); i += n) {
		risc = cx_read(ch->ctrl_start + 4 * i);
		/* No consideration for bits 63-32 */

		pr_warn("%s:   (0x%08x) iq %x: ", dev->name,
			ch->ctrl_start + 4 * i, i);
		n = cx23885_risc_decode(risc);
		for (j = 1; j < n; j++) {
			risc = cx_read(ch->ctrl_start + 4 * (i + j));
			pr_warn("%s:   iq %x: 0x%08x [ arg #%d ]\n",
				dev->name, i+j, risc, j);
		}
	}

	pr_warn("%s: fifo: 0x%08x -> 0x%x\n",
		dev->name, ch->fifo_start, ch->fifo_start+ch->fifo_size);
	pr_warn("%s: ctrl: 0x%08x -> 0x%x\n",
		dev->name, ch->ctrl_start, ch->ctrl_start + 6*16);
	pr_warn("%s:   ptr1_reg: 0x%08x\n",
		dev->name, cx_read(ch->ptr1_reg));
	pr_warn("%s:   ptr2_reg: 0x%08x\n",
		dev->name, cx_read(ch->ptr2_reg));
	pr_warn("%s:   cnt1_reg: 0x%08x\n",
		dev->name, cx_read(ch->cnt1_reg));
	pr_warn("%s:   cnt2_reg: 0x%08x\n",
		dev->name, cx_read(ch->cnt2_reg));
}

static void cx23885_risc_disasm(struct cx23885_tsport *port,
				struct cx23885_riscmem *risc)
{
	struct cx23885_dev *dev = port->dev;
	unsigned int i, j, n;

	pr_info("%s: risc disasm: %p [dma=0x%08lx]\n",
	       dev->name, risc->cpu, (unsigned long)risc->dma);
	for (i = 0; i < (risc->size >> 2); i += n) {
		pr_info("%s:   %04d: ", dev->name, i);
		n = cx23885_risc_decode(le32_to_cpu(risc->cpu[i]));
		for (j = 1; j < n; j++)
			pr_info("%s:   %04d: 0x%08x [ arg #%d ]\n",
				dev->name, i + j, risc->cpu[i + j], j);
		if (risc->cpu[i] == cpu_to_le32(RISC_JUMP))
			break;
	}
}

static void cx23885_clear_bridge_error(struct cx23885_dev *dev)
{
	uint32_t reg1_val, reg2_val;

	if (!dev->need_dma_reset)
		return;

	reg1_val = cx_read(TC_REQ); /* read-only */
	reg2_val = cx_read(TC_REQ_SET);

	if (reg1_val && reg2_val) {
		cx_write(TC_REQ, reg1_val);
		cx_write(TC_REQ_SET, reg2_val);
		cx_read(VID_B_DMA);
		cx_read(VBI_B_DMA);
		cx_read(VID_C_DMA);
		cx_read(VBI_C_DMA);

		dev_info(&dev->pci->dev,
			"dma in progress detected 0x%08x 0x%08x, clearing\n",
			reg1_val, reg2_val);
	}
}

static void cx23885_shutdown(struct cx23885_dev *dev)
{
	/* disable RISC controller */
	cx_write(DEV_CNTRL2, 0);

	/* Disable all IR activity */
	cx_write(IR_CNTRL_REG, 0);

	/* Disable Video A/B activity */
	cx_write(VID_A_DMA_CTL, 0);
	cx_write(VID_B_DMA_CTL, 0);
	cx_write(VID_C_DMA_CTL, 0);

	/* Disable Audio activity */
	cx_write(AUD_INT_DMA_CTL, 0);
	cx_write(AUD_EXT_DMA_CTL, 0);

	/* Disable Serial port */
	cx_write(UART_CTL, 0);

	/* Disable Interrupts */
	cx23885_irq_disable_all(dev);
	cx_write(VID_A_INT_MSK, 0);
	cx_write(VID_B_INT_MSK, 0);
	cx_write(VID_C_INT_MSK, 0);
	cx_write(AUDIO_INT_INT_MSK, 0);
	cx_write(AUDIO_EXT_INT_MSK, 0);

}

static void cx23885_reset(struct cx23885_dev *dev)
{
	dprintk(1, "%s()\n", __func__);

	cx23885_shutdown(dev);

	cx_write(PCI_INT_STAT, 0xffffffff);
	cx_write(VID_A_INT_STAT, 0xffffffff);
	cx_write(VID_B_INT_STAT, 0xffffffff);
	cx_write(VID_C_INT_STAT, 0xffffffff);
	cx_write(AUDIO_INT_INT_STAT, 0xffffffff);
	cx_write(AUDIO_EXT_INT_STAT, 0xffffffff);
	cx_write(CLK_DELAY, cx_read(CLK_DELAY) & 0x80000000);
	cx_write(PAD_CTRL, 0x00500300);

	/* clear dma in progress */
	cx23885_clear_bridge_error(dev);
	msleep(100);

	cx23885_sram_channel_setup(dev, &dev->sram_channels[SRAM_CH01],
		720*4, 0);
	cx23885_sram_channel_setup(dev, &dev->sram_channels[SRAM_CH02], 128, 0);
	cx23885_sram_channel_setup(dev, &dev->sram_channels[SRAM_CH03],
		188*4, 0);
	cx23885_sram_channel_setup(dev, &dev->sram_channels[SRAM_CH04], 128, 0);
	cx23885_sram_channel_setup(dev, &dev->sram_channels[SRAM_CH05], 128, 0);
	cx23885_sram_channel_setup(dev, &dev->sram_channels[SRAM_CH06],
		188*4, 0);
	cx23885_sram_channel_setup(dev, &dev->sram_channels[SRAM_CH07], 128, 0);
	cx23885_sram_channel_setup(dev, &dev->sram_channels[SRAM_CH08], 128, 0);
	cx23885_sram_channel_setup(dev, &dev->sram_channels[SRAM_CH09], 128, 0);

	cx23885_gpio_setup(dev);

	cx23885_irq_get_mask(dev);

	/* clear dma in progress */
	cx23885_clear_bridge_error(dev);
}


static int cx23885_pci_quirks(struct cx23885_dev *dev)
{
	dprintk(1, "%s()\n", __func__);

	/* The cx23885 bridge has a weird bug which causes NMI to be asserted
	 * when DMA begins if RDR_TLCTL0 bit4 is not cleared. It does not
	 * occur on the cx23887 bridge.
	 */
	if (dev->bridge == CX23885_BRIDGE_885)
		cx_clear(RDR_TLCTL0, 1 << 4);

	/* clear dma in progress */
	cx23885_clear_bridge_error(dev);
	return 0;
}

static int get_resources(struct cx23885_dev *dev)
{
	if (request_mem_region(pci_resource_start(dev->pci, 0),
			       pci_resource_len(dev->pci, 0),
			       dev->name))
		return 0;

	pr_err("%s: can't get MMIO memory @ 0x%llx\n",
	       dev->name, (unsigned long long)pci_resource_start(dev->pci, 0));

	return -EBUSY;
}

static int cx23885_init_tsport(struct cx23885_dev *dev,
	struct cx23885_tsport *port, int portno)
{
	dprintk(1, "%s(portno=%d)\n", __func__, portno);

	/* Transport bus init dma queue  - Common settings */
	port->dma_ctl_val        = 0x11; /* Enable RISC controller and Fifo */
	port->ts_int_msk_val     = 0x1111; /* TS port bits for RISC */
	port->vld_misc_val       = 0x0;
	port->hw_sop_ctrl_val    = (0x47 << 16 | 188 << 4);

	spin_lock_init(&port->slock);
	port->dev = dev;
	port->nr = portno;

	INIT_LIST_HEAD(&port->mpegq.active);
	mutex_init(&port->frontends.lock);
	INIT_LIST_HEAD(&port->frontends.felist);
	port->frontends.active_fe_id = 0;

	/* This should be hardcoded allow a single frontend
	 * attachment to this tsport, keeping the -dvb.c
	 * code clean and safe.
	 */
	if (!port->num_frontends)
		port->num_frontends = 1;

	switch (portno) {
	case 1:
		port->reg_gpcnt          = VID_B_GPCNT;
		port->reg_gpcnt_ctl      = VID_B_GPCNT_CTL;
		port->reg_dma_ctl        = VID_B_DMA_CTL;
		port->reg_lngth          = VID_B_LNGTH;
		port->reg_hw_sop_ctrl    = VID_B_HW_SOP_CTL;
		port->reg_gen_ctrl       = VID_B_GEN_CTL;
		port->reg_bd_pkt_status  = VID_B_BD_PKT_STATUS;
		port->reg_sop_status     = VID_B_SOP_STATUS;
		port->reg_fifo_ovfl_stat = VID_B_FIFO_OVFL_STAT;
		port->reg_vld_misc       = VID_B_VLD_MISC;
		port->reg_ts_clk_en      = VID_B_TS_CLK_EN;
		port->reg_src_sel        = VID_B_SRC_SEL;
		port->reg_ts_int_msk     = VID_B_INT_MSK;
		port->reg_ts_int_stat    = VID_B_INT_STAT;
		port->sram_chno          = SRAM_CH03; /* VID_B */
		port->pci_irqmask        = 0x02; /* VID_B bit1 */
		break;
	case 2:
		port->reg_gpcnt          = VID_C_GPCNT;
		port->reg_gpcnt_ctl      = VID_C_GPCNT_CTL;
		port->reg_dma_ctl        = VID_C_DMA_CTL;
		port->reg_lngth          = VID_C_LNGTH;
		port->reg_hw_sop_ctrl    = VID_C_HW_SOP_CTL;
		port->reg_gen_ctrl       = VID_C_GEN_CTL;
		port->reg_bd_pkt_status  = VID_C_BD_PKT_STATUS;
		port->reg_sop_status     = VID_C_SOP_STATUS;
		port->reg_fifo_ovfl_stat = VID_C_FIFO_OVFL_STAT;
		port->reg_vld_misc       = VID_C_VLD_MISC;
		port->reg_ts_clk_en      = VID_C_TS_CLK_EN;
		port->reg_src_sel        = 0;
		port->reg_ts_int_msk     = VID_C_INT_MSK;
		port->reg_ts_int_stat    = VID_C_INT_STAT;
		port->sram_chno          = SRAM_CH06; /* VID_C */
		port->pci_irqmask        = 0x04; /* VID_C bit2 */
		break;
	default:
		BUG();
	}

	return 0;
}

static void cx23885_dev_checkrevision(struct cx23885_dev *dev)
{
	switch (cx_read(RDR_CFG2) & 0xff) {
	case 0x00:
		/* cx23885 */
		dev->hwrevision = 0xa0;
		break;
	case 0x01:
		/* CX23885-12Z */
		dev->hwrevision = 0xa1;
		break;
	case 0x02:
		/* CX23885-13Z/14Z */
		dev->hwrevision = 0xb0;
		break;
	case 0x03:
		if (dev->pci->device == 0x8880) {
			/* CX23888-21Z/22Z */
			dev->hwrevision = 0xc0;
		} else {
			/* CX23885-14Z */
			dev->hwrevision = 0xa4;
		}
		break;
	case 0x04:
		if (dev->pci->device == 0x8880) {
			/* CX23888-31Z */
			dev->hwrevision = 0xd0;
		} else {
			/* CX23885-15Z, CX23888-31Z */
			dev->hwrevision = 0xa5;
		}
		break;
	case 0x0e:
		/* CX23887-15Z */
		dev->hwrevision = 0xc0;
		break;
	case 0x0f:
		/* CX23887-14Z */
		dev->hwrevision = 0xb1;
		break;
	default:
		pr_err("%s() New hardware revision found 0x%x\n",
		       __func__, dev->hwrevision);
	}
	if (dev->hwrevision)
		pr_info("%s() Hardware revision = 0x%02x\n",
			__func__, dev->hwrevision);
	else
		pr_err("%s() Hardware revision unknown 0x%x\n",
		       __func__, dev->hwrevision);
}

/* Find the first v4l2_subdev member of the group id in hw */
struct v4l2_subdev *cx23885_find_hw(struct cx23885_dev *dev, u32 hw)
{
	struct v4l2_subdev *result = NULL;
	struct v4l2_subdev *sd;

	spin_lock(&dev->v4l2_dev.lock);
	v4l2_device_for_each_subdev(sd, &dev->v4l2_dev) {
		if (sd->grp_id == hw) {
			result = sd;
			break;
		}
	}
	spin_unlock(&dev->v4l2_dev.lock);
	return result;
}

static int cx23885_dev_setup(struct cx23885_dev *dev)
{
	int i;

	spin_lock_init(&dev->pci_irqmask_lock);
	spin_lock_init(&dev->slock);

	mutex_init(&dev->lock);
	mutex_init(&dev->gpio_lock);

	atomic_inc(&dev->refcount);

	dev->nr = cx23885_devcount++;
	sprintf(dev->name, "cx23885[%d]", dev->nr);

	/* Configure the internal memory */
	if (dev->pci->device == 0x8880) {
		/* Could be 887 or 888, assume an 888 default */
		dev->bridge = CX23885_BRIDGE_888;
		/* Apply a sensible clock frequency for the PCIe bridge */
		dev->clk_freq = 50000000;
		dev->sram_channels = cx23887_sram_channels;
	} else
	if (dev->pci->device == 0x8852) {
		dev->bridge = CX23885_BRIDGE_885;
		/* Apply a sensible clock frequency for the PCIe bridge */
		dev->clk_freq = 28000000;
		dev->sram_channels = cx23885_sram_channels;
	} else
		BUG();

	dprintk(1, "%s() Memory configured for PCIe bridge type %d\n",
		__func__, dev->bridge);

	/* board config */
	dev->board = UNSET;
	if (card[dev->nr] < cx23885_bcount)
		dev->board = card[dev->nr];
	for (i = 0; UNSET == dev->board  &&  i < cx23885_idcount; i++)
		if (dev->pci->subsystem_vendor == cx23885_subids[i].subvendor &&
		    dev->pci->subsystem_device == cx23885_subids[i].subdevice)
			dev->board = cx23885_subids[i].card;
	if (UNSET == dev->board) {
		dev->board = CX23885_BOARD_UNKNOWN;
		cx23885_card_list(dev);
	}

	if (dev->pci->device == 0x8852) {
		/* no DIF on cx23885, so no analog tuner support possible */
		if (dev->board == CX23885_BOARD_HAUPPAUGE_QUADHD_ATSC)
			dev->board = CX23885_BOARD_HAUPPAUGE_QUADHD_ATSC_885;
		else if (dev->board == CX23885_BOARD_HAUPPAUGE_QUADHD_DVB)
			dev->board = CX23885_BOARD_HAUPPAUGE_QUADHD_DVB_885;
	}

	/* If the user specific a clk freq override, apply it */
	if (cx23885_boards[dev->board].clk_freq > 0)
		dev->clk_freq = cx23885_boards[dev->board].clk_freq;

	if (dev->board == CX23885_BOARD_HAUPPAUGE_IMPACTVCBE &&
		dev->pci->subsystem_device == 0x7137) {
		/* Hauppauge ImpactVCBe device ID 0x7137 is populated
		 * with an 888, and a 25Mhz crystal, instead of the
		 * usual third overtone 50Mhz. The default clock rate must
		 * be overridden so the cx25840 is properly configured
		 */
		dev->clk_freq = 25000000;
	}

	dev->pci_bus  = dev->pci->bus->number;
	dev->pci_slot = PCI_SLOT(dev->pci->devfn);
	cx23885_irq_add(dev, 0x001f00);

	/* External Master 1 Bus */
	dev->i2c_bus[0].nr = 0;
	dev->i2c_bus[0].dev = dev;
	dev->i2c_bus[0].reg_stat  = I2C1_STAT;
	dev->i2c_bus[0].reg_ctrl  = I2C1_CTRL;
	dev->i2c_bus[0].reg_addr  = I2C1_ADDR;
	dev->i2c_bus[0].reg_rdata = I2C1_RDATA;
	dev->i2c_bus[0].reg_wdata = I2C1_WDATA;
	dev->i2c_bus[0].i2c_period = (0x9d << 24); /* 100kHz */

	/* External Master 2 Bus */
	dev->i2c_bus[1].nr = 1;
	dev->i2c_bus[1].dev = dev;
	dev->i2c_bus[1].reg_stat  = I2C2_STAT;
	dev->i2c_bus[1].reg_ctrl  = I2C2_CTRL;
	dev->i2c_bus[1].reg_addr  = I2C2_ADDR;
	dev->i2c_bus[1].reg_rdata = I2C2_RDATA;
	dev->i2c_bus[1].reg_wdata = I2C2_WDATA;
	dev->i2c_bus[1].i2c_period = (0x9d << 24); /* 100kHz */

	/* Internal Master 3 Bus */
	dev->i2c_bus[2].nr = 2;
	dev->i2c_bus[2].dev = dev;
	dev->i2c_bus[2].reg_stat  = I2C3_STAT;
	dev->i2c_bus[2].reg_ctrl  = I2C3_CTRL;
	dev->i2c_bus[2].reg_addr  = I2C3_ADDR;
	dev->i2c_bus[2].reg_rdata = I2C3_RDATA;
	dev->i2c_bus[2].reg_wdata = I2C3_WDATA;
	dev->i2c_bus[2].i2c_period = (0x07 << 24); /* 1.95MHz */

	if ((cx23885_boards[dev->board].portb == CX23885_MPEG_DVB) ||
		(cx23885_boards[dev->board].portb == CX23885_MPEG_ENCODER))
		cx23885_init_tsport(dev, &dev->ts1, 1);

	if ((cx23885_boards[dev->board].portc == CX23885_MPEG_DVB) ||
		(cx23885_boards[dev->board].portc == CX23885_MPEG_ENCODER))
		cx23885_init_tsport(dev, &dev->ts2, 2);

	if (get_resources(dev) < 0) {
		pr_err("CORE %s No more PCIe resources for subsystem: %04x:%04x\n",
		       dev->name, dev->pci->subsystem_vendor,
		       dev->pci->subsystem_device);

		cx23885_devcount--;
		return -ENODEV;
	}

	/* PCIe stuff */
	dev->lmmio = ioremap(pci_resource_start(dev->pci, 0),
			     pci_resource_len(dev->pci, 0));

	dev->bmmio = (u8 __iomem *)dev->lmmio;

	pr_info("CORE %s: subsystem: %04x:%04x, board: %s [card=%d,%s]\n",
		dev->name, dev->pci->subsystem_vendor,
		dev->pci->subsystem_device, cx23885_boards[dev->board].name,
		dev->board, card[dev->nr] == dev->board ?
		"insmod option" : "autodetected");

	cx23885_pci_quirks(dev);

	/* Assume some sensible defaults */
	dev->tuner_type = cx23885_boards[dev->board].tuner_type;
	dev->tuner_addr = cx23885_boards[dev->board].tuner_addr;
	dev->tuner_bus = cx23885_boards[dev->board].tuner_bus;
	dev->radio_type = cx23885_boards[dev->board].radio_type;
	dev->radio_addr = cx23885_boards[dev->board].radio_addr;

	dprintk(1, "%s() tuner_type = 0x%x tuner_addr = 0x%x tuner_bus = %d\n",
		__func__, dev->tuner_type, dev->tuner_addr, dev->tuner_bus);
	dprintk(1, "%s() radio_type = 0x%x radio_addr = 0x%x\n",
		__func__, dev->radio_type, dev->radio_addr);

	/* The cx23417 encoder has GPIO's that need to be initialised
	 * before DVB, so that demodulators and tuners are out of
	 * reset before DVB uses them.
	 */
	if ((cx23885_boards[dev->board].portb == CX23885_MPEG_ENCODER) ||
		(cx23885_boards[dev->board].portc == CX23885_MPEG_ENCODER))
			cx23885_mc417_init(dev);

	/* init hardware */
	cx23885_reset(dev);

	cx23885_i2c_register(&dev->i2c_bus[0]);
	cx23885_i2c_register(&dev->i2c_bus[1]);
	cx23885_i2c_register(&dev->i2c_bus[2]);
	cx23885_card_setup(dev);
	c